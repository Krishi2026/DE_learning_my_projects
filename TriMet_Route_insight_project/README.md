# ğŸš TriMet Route Insight â€“ Real-Time Transit Data Pipeline (GCP)

A real-time data engineering project designed to collect, validate, and visualize GPS data from TriMet public transit vehicles using Google Cloud Platform (GCP).

---

## ğŸ“Œ Project Overview

This project simulates and processes real-time transit data using Google Cloud services. It fetches GPS breadcrumb data from TriMetâ€™s public API, publishes it via Pub/Sub, validates and enriches the data, and stores it in a PostgreSQL database. Processed data is then visualized using Mapbox GL on interactive maps.

---

## ğŸ§© Key Features

- ğŸ”„ **Real-Time Ingestion**: Publish TriMet vehicle GPS data to Google Cloud Pub/Sub
- ğŸ§ª **Data Validation & Enrichment**:
  - GPS bounds checks
  - Negative value handling
  - Trip ID and timestamp consistency
  - Speed calculation and outlier detection using z-score
- ğŸ—ƒï¸ **Storage**:
  - Processed data stored in `Trip` and `Breadcrumb` tables in PostgreSQL
- ğŸ—ºï¸ **Visualization**:
  - Visualize vehicle routes and speeds using **Mapbox GL** and **GeoJSON**

---

## âš™ï¸ Technologies Used

- **Google Cloud Platform**
  - Pub/Sub (for streaming)
  - Service Accounts (authentication)
- **Python**
  - Pandas, JSON, threading
- **PostgreSQL**
  - Tables: `Trip`, `Breadcrumb`
- **Mapbox GL**
  - For dynamic route mapping
- **GeoJSON**
  - Format for spatial data
- **Git / GitHub** for version control

---

## ğŸ“ Project Structure

```bash
.
â”œâ”€â”€ publisher.py         # Pulls TriMet API data and publishes to GCP Pub/Sub
â”œâ”€â”€ Subscriber.py        # Subscriber with validation, enrichment, and PostgreSQL ingestion
â”œâ”€â”€ subscriber.py        # Writes raw messages to file
â”œâ”€â”€ processjson.py       # Data validation, speed calc, DB insertions from JSON files
â”œâ”€â”€ pub.sh               # Shell script to run the publisher
â”œâ”€â”€ vehicle_ids.csv      # Input list of vehicle IDs to track
â”œâ”€â”€ received_msg/        # Directory for storing raw JSON messages
